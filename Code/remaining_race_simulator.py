# ============================================================# ðŸŽï¸ Track Score Matrix Builder (Pace Score)# ============================================================from __future__ import annotationsimport numpy as npimport pandas as pdfrom pathlib import Pathimport reimport sys, importlib# ============================================================# ðŸ”§ CONFIGURATION RELOAD PATCH# ============================================================try:    # If running under the global runner    if "Code.config" in sys.modules:        config = sys.modules["Code.config"]        importlib.reload(config)    else:        # Standalone fallback        import Code.config as config        sys.modules["Code.config"] = configexcept Exception as e:    print(f"[WARN] Could not reload Code.config dynamically: {e}")    import Code.config as config# ============================================================# âš™ï¸ GLOBAL VARIABLES# ============================================================YEAR  = config.YEARROUND = config.ROUNDROOT  = Path.home() / "Documents" / "F1-Project-Folder"DATA  = ROOT / "Data_Processed"FASTF1_DIR = DATA / "fastf1"OUT_DIR    = DATA / "wdc_prediction"OUT_DIR.mkdir(parents=True, exist_ok=True)OUT_FILE   = OUT_DIR / "Track_Score_matrix.csv"print(f"âœ… Remaining Race Simulator Config Loaded: YEAR={YEAR}, ROUND={ROUND}")# --- Parameters ---S_MAX = 100.0        # Pace for P1S_MIN = 12.0         # Minimum pace floor per eventHALF_LIFE_POS = 7.0  # Grid positions to halve the paceYEARS = list(range(2018, YEAR + 1))EVENTS_2025_ORDER = [    "Australian Grand Prix","Bahrain Grand Prix","Saudi Arabian Grand Prix","Japanese Grand Prix",    "Chinese Grand Prix","Miami Grand Prix","Emilia Romagna Grand Prix","Monaco Grand Prix",    "Canadian Grand Prix","Spanish Grand Prix","Austrian Grand Prix","British Grand Prix",    "Hungarian Grand Prix","Belgian Grand Prix","Dutch Grand Prix","Italian Grand Prix",    "Azerbaijan Grand Prix","Singapore Grand Prix","United States Grand Prix","Mexico City Grand Prix",    "SÃ£o Paulo Grand Prix","Las Vegas Grand Prix","Qatar Grand Prix","Abu Dhabi Grand Prix"]ALLOWED_EVENTS = set(EVENTS_2025_ORDER)# ============================================================# âš™ï¸ CORE FUNCTIONS# ============================================================def _parse_round_from_filename(p: Path) -> int | None:    m = re.search(r"_R(\d+)_features\.csv$", p.name)    return int(m.group(1)) if m else Nonedef _pace_from_grid(grid_pos: pd.Series) -> pd.Series:    """Exponential decay based on grid position, floored at S_MIN and rounded."""    g = pd.to_numeric(grid_pos, errors="coerce").to_numpy(dtype=float)    pace = S_MAX * np.power(0.5, (g - 1.0) / HALF_LIFE_POS)    pace = np.maximum(pace, S_MIN)    return pd.Series(np.round(pace, 2), index=grid_pos.index)# ============================================================# ðŸš— BUILD PACE MATRIX# ============================================================def build_track_score_matrix():    # --- Step 1: Identify all drivers in current season ---    files_curr = sorted((FASTF1_DIR / str(YEAR)).glob(f"{YEAR}_R*_features.csv"),                        key=lambda p: _parse_round_from_filename(p) or 999)    if not files_curr:        raise RuntimeError(f"No {YEAR} feature files found in {FASTF1_DIR}/{YEAR}/")    current_drivers = set()    for f in files_curr:        df = pd.read_csv(f)        if "Abbreviation" not in df.columns:            continue        current_drivers.update(df["Abbreviation"].dropna().astype(str).unique())    current_drivers = sorted(current_drivers)    # --- Step 2: Collect pace scores across all years ---    records = []    for y in YEARS:        ydir = FASTF1_DIR / str(y)        if not ydir.exists():            continue        for f in ydir.glob(f"{y}_R*_features.csv"):            try:                df = pd.read_csv(f)            except Exception:                continue            if not {"Abbreviation", "GridPosition", "EventName"}.issubset(df.columns):                continue            event = str(df["EventName"].iloc[0])            if event not in ALLOWED_EVENTS:                continue            pace = _pace_from_grid(df["GridPosition"])            tmp = pd.DataFrame({                "Abbreviation": df["Abbreviation"].astype(str),                "EventName": event,                "Pace100": pace            })            records.append(tmp)    if not records:        raise RuntimeError("No valid pace data found for pace matrix computation.")    tall = pd.concat(records, ignore_index=True)    tall = tall[tall["Abbreviation"].isin(current_drivers)]    # --- Step 3: Aggregate and pivot ---    agg = (tall.groupby(["Abbreviation", "EventName"], as_index=False)["Pace100"].mean())    wide = (agg            .pivot_table(index="Abbreviation", columns="EventName", values="Pace100", aggfunc="mean")            .reindex(index=current_drivers, columns=EVENTS_2025_ORDER)            .fillna(15.24))    # âœ… Round all numeric values to 2 decimals    wide = wide.round(2)    # --- Step 4: Clean up and save ---    if "DOO" in wide.index:        wide = wide.drop(index="DOO")    # === updated output path ===    OUT_FILE = OUT_DIR / "Pace_Score_matrix.csv"    wide = wide.reset_index()    wide.to_csv(OUT_FILE, index=False, float_format="%.2f")    print(f"âœ… Pace Score Matrix saved -> {OUT_FILE}")    print(f"Drivers: {wide.shape[0]} | Events: {wide.shape[1] - 1}")    return wide# ============================================================# ðŸ EXECUTE# ============================================================if __name__ == "__main__":    build_track_score_matrix()                        # ============================================================#  Track Record Matrix Builder (2018â€“2025 Finishing Data)# ============================================================# This builds a driver Ã— track matrix of historical performance scores# Each cell represents the driverâ€™s average finishing strength on that track# Formula:#   P1 = 100 ... P10 = 20 ... P20 = 1# New drivers (no history) -> 15def build_track_record_matrix():    # --- Step 1: Current grid detection (from current year) ---    files_curr = sorted((FASTF1_DIR / str(YEAR)).glob(f"{YEAR}_R*_features.csv"),                        key=lambda p: _parse_round_from_filename(p) or 999)    if not files_curr:        raise RuntimeError(f"No {YEAR} feature files found in {FASTF1_DIR}/{YEAR}/")    current_drivers = set()    for f in files_curr:        df = pd.read_csv(f)        if "Abbreviation" in df.columns:            current_drivers.update(df["Abbreviation"].dropna().astype(str).unique())    current_drivers = sorted(current_drivers)    # --- Step 2: Define scoring scale ---    position_score = {        1:100, 2:90, 3:80, 4:65, 5:50, 6:40, 7:32, 8:26, 9:23, 10:20,        11:15, 12:12, 13:10, 14:8, 15:6, 16:5, 17:4, 18:3, 19:2, 20:1    }    # --- Step 3: Collect all race records (2018 â†’ current year) ---    records = []    for y in range(2018, YEAR + 1):        ydir = FASTF1_DIR / str(y)        if not ydir.exists():            continue        for f in ydir.glob(f"{y}_R*_features.csv"):            try:                df = pd.read_csv(f)            except Exception:                continue            # Required columns            if not {"Abbreviation", "FinishPosition", "EventName"}.issubset(df.columns):                continue            event = str(df["EventName"].iloc[0])            if event not in ALLOWED_EVENTS:                continue            # Map positions to scores            df["FinishPosition"] = pd.to_numeric(df["FinishPosition"], errors="coerce")            df["Score"] = df["FinishPosition"].map(lambda x: position_score.get(int(x), 1) if pd.notna(x) else 1)            tmp = df[["Abbreviation", "EventName", "Score"]].copy()            tmp["Abbreviation"] = tmp["Abbreviation"].astype(str)            records.append(tmp)    if not records:        raise RuntimeError("No usable race data found for Track Record Matrix.")    tall = pd.concat(records, ignore_index=True)    tall = tall[tall["Abbreviation"].isin(current_drivers)]    # --- Step 4: Aggregate average per driver per track ---    agg = (        tall.groupby(["Abbreviation", "EventName"], as_index=False)["Score"]        .mean()        .round(2)    )    # --- Step 5: Pivot to matrix format ---    wide = (        agg.pivot_table(index="Abbreviation", columns="EventName", values="Score", aggfunc="mean")        .reindex(index=current_drivers, columns=EVENTS_2025_ORDER)        .fillna(15.00)    )    #  Round to 2 decimals    wide = wide.round(2)    # Drop DOO if exists    if "DOO" in wide.index:        wide = wide.drop(index="DOO")    # --- Step 6: Save ---    OUT_FILE_RECORD = OUT_DIR / "Track_Record_Matrix.csv"    wide = wide.reset_index()    wide.to_csv(OUT_FILE_RECORD, index=False, float_format="%.2f")    print(f"âœ… Track Record Matrix saved -> {OUT_FILE_RECORD}")    print(f"Drivers: {wide.shape[0]} | Events: {wide.shape[1]-1}")    return wide# ============================================================#  EXECUTE# ============================================================if __name__ == "__main__":    build_track_record_matrix()        # ============================================================#  Multi-Race Win Probability Matrix (Weighted Linear Model)# ============================================================# ------------------------------------------------------------# Config# ------------------------------------------------------------YEAR  = config.YEARROUND = config.ROUNDROOT  = Path.home() / "Documents" / "F1-Project-Folder"DATA  = ROOT / "Data_Processed"IN_FILE  = DATA / "quali_feat" / "Champ_Rating" / f"all_scores_after_quali_r{ROUND}_{YEAR}.csv"PACE_FILE   = DATA / "wdc_prediction" / "Pace_Score_matrix.csv"TRACK_FILE  = DATA / "wdc_prediction" / "Track_Record_Matrix.csv"OUT_FILE    = DATA / "wdc_prediction" / f"win_probability_matrix_remaining_{YEAR}.csv"# ---- Weights ----W_CHAMP = 10W_FORM  = 45W_PACE  = 25W_TRACK = 20# ------------------------------------------------------------# Load Data# ------------------------------------------------------------df_base = pd.read_csv(IN_FILE)df_base.columns = [c.strip() for c in df_base.columns]df_base["Abbreviation"] = df_base["Abbreviation"].str.upper().str.strip()for c in ["Champ_Rating", "Rolling_Form", "PaceScore"]:    df_base[c] = pd.to_numeric(df_base[c], errors="coerce").fillna(0.0)df_pace   = pd.read_csv(PACE_FILE)df_record = pd.read_csv(TRACK_FILE)# Identify remaining events (round+1 .. end of calendar)events = [c for c in df_pace.columns if c in df_record.columns and c != "Abbreviation"]remaining = events[ROUND:]   # starting after current roundif not remaining:    raise ValueError("No remaining races found for this season based on round index.")# ------------------------------------------------------------# Compute probabilities for each remaining race# ------------------------------------------------------------driver_probs = {"Abbreviation": df_base["Abbreviation"].tolist()}for race in remaining:    # Merge data for the given race    merged = df_base.merge(df_pace[["Abbreviation", race]], on="Abbreviation", how="left")    merged = merged.merge(df_record[["Abbreviation", race]], on="Abbreviation", suffixes=("_pace", "_record"), how="left")    # Clean missing data    merged[race + "_pace"]   = pd.to_numeric(merged[race + "_pace"], errors="coerce").fillna(15)    merged[race + "_record"] = pd.to_numeric(merged[race + "_record"], errors="coerce").fillna(15)    # Weighted score    merged["RawScore"] = (        W_CHAMP * merged["Champ_Rating"] +        W_FORM  * merged["Rolling_Form"] +        W_PACE  * merged[race + "_pace"] +        W_TRACK * merged[race + "_record"]    )    # Normalize to percentage (sum = 100)    merged["WinProb"] = (merged["RawScore"] / merged["RawScore"].sum()) * 100    merged["WinProb"] = merged["WinProb"].round(7)    driver_probs[race] = merged["WinProb"].tolist()# ------------------------------------------------------------# Create final matrix# ------------------------------------------------------------final = pd.DataFrame(driver_probs)final = final.set_index("Abbreviation")final = final.round(7)final.to_csv(OUT_FILE, float_format="%.7f")print(f"âœ… Win probability matrix created for remaining races â†’ {OUT_FILE}")print(f"Included races: {len(remaining)} ({', '.join(remaining)})")print(final.head(10))# ============================================================#  Monte Carlo Simulation (Step 1: Finish Position Probabilities)# ============================================================# ------------------------------------------------------------# Config# ------------------------------------------------------------YEAR  = config.YEARROUND = config.ROUNDROOT  = Path.home() / "Documents" / "F1-Project-Folder"DATA  = ROOT / "Data_Processed"IN_FILE  = DATA / "wdc_prediction" / f"win_probability_matrix_remaining_{YEAR}.csv"OUT_FILE = DATA / "wdc_prediction" / f"finish_position_probabilities_{YEAR}.csv"N_ITER   = 1_000_000CHUNK    = 50_000RNG      = np.random.default_rng(42)TEMP     = 5    # softmax temperature to even out skewEPS      = 1e-12# ------------------------------------------------------------# Load Win Probability Matrix# ------------------------------------------------------------df = pd.read_csv(IN_FILE)drivers = df["Abbreviation"].tolist()races = [c for c in df.columns if c != "Abbreviation"]# ------------------------------------------------------------# Helper# ------------------------------------------------------------def softmax(x, temp=1.0):    x = np.array(x, dtype=float)    x = x / temp    e = np.exp(x - np.max(x))    return e / e.sum()# ------------------------------------------------------------# Simulate each race separately# ------------------------------------------------------------results = []for race in races:    probs = df[race].to_numpy(dtype=float)    probs = np.clip(probs, EPS, None)    probs = softmax(probs, temp=TEMP)    probs /= probs.sum()    n = len(probs)    pos_counts = np.zeros((n, n), dtype=np.int64)    remaining = N_ITER    while remaining > 0:        m = min(CHUNK, remaining)        u = RNG.random((m, n))        g = -np.log(-np.log(u))        scores = np.log(probs) + g        order = np.argsort(-scores, axis=1)        for k in range(n):            idx_at_k = order[:, k]            bc = np.bincount(idx_at_k, minlength=n)            pos_counts[:, k] += bc        remaining -= m    pos_prob = pos_counts / float(N_ITER)    pos_prob[pos_prob < EPS] = 0.0    pos_prob *= 100.0  # convert to percentage    out = pd.DataFrame({"Abbreviation": drivers})    for k in range(n):        out[f"P{k+1}"] = pos_prob[:, k].round(7)    out.insert(0, "Race", race)    results.append(out)# ------------------------------------------------------------# Combine and Save# ------------------------------------------------------------final = pd.concat(results, ignore_index=True)final.to_csv(OUT_FILE, index=False, float_format="%.7f")print(f"âœ… Monte Carlo Step 1 complete â†’ {OUT_FILE}")print(final.head(10))# ============================================================#  Monte Carlo Step 2 â€” Final Order Prediction per Race# ============================================================IN_FILE  = DATA / "wdc_prediction" / f"finish_position_probabilities_{YEAR}.csv"OUT_DIR  = DATA / "wdc_prediction" / "final_predictions"OUT_DIR.mkdir(parents=True, exist_ok=True)N_ITER_POS = 1_000_000RNG = np.random.default_rng(123)MIN_PROB = 1e-15# ------------------------------------------------------------# Load finish-position probabilities# ------------------------------------------------------------df = pd.read_csv(IN_FILE)if "Race" not in df.columns or "Abbreviation" not in df.columns:    raise KeyError("Missing required columns 'Race' or 'Abbreviation' in input file.")races = df["Race"].unique().tolist()# ------------------------------------------------------------# Process each race independently# ------------------------------------------------------------for race in races:    race_df = df[df["Race"] == race].copy()    drivers = race_df["Abbreviation"].tolist()    # detect position columns P1â€¦Pn    p_cols = [c for c in race_df.columns if re.fullmatch(r"P\d+", c)]    if not p_cols:        print(f"âš ï¸ No Pk columns found for {race}, skipping.")        continue    n = len(drivers)    expected = [f"P{i}" for i in range(1, n+1)]    p_cols = [c for c in expected if c in race_df.columns]    for c in p_cols:        race_df[c] = pd.to_numeric(race_df[c], errors="coerce").fillna(0.0).clip(0.0, 100.0)        race_df[c] /= 100.0   # convert to 0â€“1    race_df = race_df.set_index("Abbreviation")    remaining = race_df.index.tolist()    final_order = []    # sequentially determine finishing order    for k in range(1, len(remaining)+1):        col = f"P{k}"        probs = race_df.loc[remaining, col].to_numpy(dtype=float)        if probs.sum() <= 0:            probs = np.ones_like(probs) / len(probs)        else:            probs /= probs.sum()        counts = RNG.multinomial(N_ITER_POS, probs)        w_idx = int(np.argmax(counts))        winner = remaining[w_idx]        final_order.append(winner)        remaining.pop(w_idx)    # --------------------------------------------------------    # Save race-specific final order    # --------------------------------------------------------    out = pd.DataFrame({        "GrandPrix": race,        "Position": [f"P{i}" for i in range(1, len(final_order)+1)],        "Abbreviation": final_order    })    safe_name = re.sub(r"[^A-Za-z0-9]+", "_", race)    OUT_PATH = OUT_DIR / f"{race}_final_order.csv"    out.to_csv(OUT_PATH, index=False)    print(f"âœ… Saved final order â†’ {OUT_PATH}")    print(out.head(5))                                        