#-------------------------------# driver_vs_track_score_matrix #-------------------------------from __future__ import annotationsfrom pathlib import Pathimport pandas as pdimport numpy as npimport refrom typing import List, Optional, Tuple# -------- Config --------ROOT = Path.home() / "Documents" / "F1-Project-Folder"PROC_DIR = ROOT / "Data_Processed" / "fastf1"OUT_DIR  = ROOT / "Data_Processed" / "wdc_prediction"OUT_FILE = OUT_DIR / "driver_vs_track_score_matrix.csv"CALENDAR_2025 = [    "Bahrain Grand Prix","Saudi Arabian Grand Prix","Australian Grand Prix",    "Japanese Grand Prix","Chinese Grand Prix","Miami Grand Prix",    "Emilia Romagna Grand Prix","Monaco Grand Prix","Canadian Grand Prix",    "Spanish Grand Prix","Austrian Grand Prix","British Grand Prix",    "Hungarian Grand Prix","Belgian Grand Prix","Dutch Grand Prix",    "Italian Grand Prix","Azerbaijan Grand Prix","Singapore Grand Prix",    "United States Grand Prix","Mexican Grand Prix","Brazilian Grand Prix",    "Las Vegas Grand Prix","Qatar Grand Prix","Abu Dhabi Grand Prix"]# Finishing position -> score (podiums valued more, tails still distinct)POSITION_SCORE = {    1: 100,    2: 90,    3: 82,    4: 75,    5: 69,    6: 63,    7: 58,    8: 53,    9: 49,    10: 45,    11: 41,    12: 37,    13: 34,    14: 31,    15: 28,    16: 25,    17: 22,    18: 19,    19: 17,    20: 15}# Column fallbacks we’ll try per fileDRIVER_KEYS   = ["Abbreviation","Driver","DriverAbbreviation","Code"]FINISH_KEYS   = ["FinishPosition","Position","FinishPos"]EVENT_KEYS    = ["EventName","Track","GrandPrix","Country"]def _feature_files(years=range(2018, 2026)):    files = []    for y in years:        ydir = PROC_DIR / str(y)        if ydir.exists():            files += list(ydir.glob(f"{y}_R*_features.csv"))    return sorted(files)def _pick_col(df: pd.DataFrame, choices: list[str]) -> str | None:    for c in choices:        if c in df.columns:            return c    return Nonedef _normalize_driver_col(df: pd.DataFrame) -> pd.DataFrame:    c = _pick_col(df, DRIVER_KEYS)    if c is None:        # nothing we can do with this file        return None    if c != "Abbreviation":        df = df.rename(columns={c: "Abbreviation"})    df["Abbreviation"] = df["Abbreviation"].astype(str)    return dfdef _get_2025_grid() -> set[str]:    ydir = PROC_DIR / "2025"    if not ydir.exists():        return set()    drivers = set()    for p in sorted(ydir.glob("2025_*_features.csv")):        try:            df = pd.read_csv(p)        except Exception:            continue        df = _normalize_driver_col(df)        if df is None:            continue        drivers.update(df["Abbreviation"].dropna().astype(str).unique().tolist())    return driversdef _get_event_name(df: pd.DataFrame) -> str | None:    c = _pick_col(df, EVENT_KEYS)    if c is None:        return None    name = str(df[c].iloc[0])    # simple cleanups if needed    return namedef build_matrix() -> pd.DataFrame:    files = _feature_files()    if not files:        raise FileNotFoundError(f"No processed files under {PROC_DIR}")    grid_2025 = _get_2025_grid()    if not grid_2025:        raise RuntimeError("Could not discover 2025 grid from processed files.")    rows = []    skipped_files = 0    for f in files:        try:            df = pd.read_csv(f)        except Exception:            skipped_files += 1            continue        # Normalize driver col        df = _normalize_driver_col(df)        if df is None:            skipped_files += 1            continue        # Event name & filter to 2025 calendar        ev = _get_event_name(df)        if ev is None or ev not in CALENDAR_2025:            continue        # Keep only 2025 grid drivers        df = df[df["Abbreviation"].isin(grid_2025)]        if df.empty:            continue        # Finish position column        pos_col = _pick_col(df, FINISH_KEYS)        if pos_col is None:            skipped_files += 1            continue        pos = pd.to_numeric(df[pos_col], errors="coerce")        score = pos.map(lambda k: POSITION_SCORE.get(int(k), 0) if pd.notna(k) else 0.0)        sub = pd.DataFrame({            "Abbreviation": df["Abbreviation"].astype(str).values,            "EventName": ev,            "Score": score.values        })        rows.append(sub)    if not rows:        raise RuntimeError("No usable rows collected. Check column names in processed files.")    tall = pd.concat(rows, ignore_index=True)    # Average score per (driver, track)    avg = (tall           .groupby(["Abbreviation","EventName"], as_index=False)["Score"]           .mean())    # Pivot to matrix: rows=driver, columns=2025 tracks; fill missing with 0    mat = (avg           .pivot(index="Abbreviation", columns="EventName", values="Score")           .reindex(columns=CALENDAR_2025)     # consistent 2025 column order           .fillna(0.0)           .reset_index())    OUT_DIR.mkdir(parents=True, exist_ok=True)    mat.to_csv(OUT_FILE, index=False)    print(f"✅ Driver×Track matrix saved -> {OUT_FILE}")    return matif __name__ == "__main__":    build_matrix()                            #-----------------------------#Pace Score#-----------------------------# ---------------- CONFIG ----------------ROOT = Path("/Users/ravish/Documents/F1-Project-Folder/Data_Processed/fastf1")OUT_DIR = Path("/Users/ravish/Documents/F1-Project-Folder/Data_Processed/wdc_prediction")OUT_CSV = OUT_DIR / "pace_by_track_gridexp_2018to2025.csv"YEARS = list(range(2018, 2026))  # 2018..2025 inclusiveDRIVER_COL = "Abbreviation"EVENT_COL  = "EventName"GRID_COL   = "GridPosition"# Pace mapping (you can tweak)S_MAX = 100.0        # pace for P1S_MIN = 12.0         # minimum pace floor per eventHALF_LIFE_POS = 7.0  # positions to halve the pace (gentler = larger)# Fill when a current driver has never raced a 2025 trackFILL_NEVER_RACED = 15.24# 2025 calendar (order locked here)EVENTS_2025_ORDER = [    "Australian Grand Prix",    "Bahrain Grand Prix",    "Saudi Arabian Grand Prix",    "Japanese Grand Prix",    "Chinese Grand Prix",    "Miami Grand Prix",    "Emilia Romagna Grand Prix",    "Monaco Grand Prix",    "Canadian Grand Prix",    "Spanish Grand Prix",    "Austrian Grand Prix",    "British Grand Prix",    "Hungarian Grand Prix",    "Belgian Grand Prix",    "Dutch Grand Prix",    "Italian Grand Prix",    "Azerbaijan Grand Prix",    "Singapore Grand Prix",    "United States Grand Prix",    "Mexico City Grand Prix",    "São Paulo Grand Prix",    "Las Vegas Grand Prix",    "Qatar Grand Prix",    "Abu Dhabi Grand Prix",]ALLOWED_EVENTS = set(EVENTS_2025_ORDER)# ---------------- HELPERS ----------------def _parse_round_from_filename(p: Path) -> int | None:    m = re.search(r"_R(\d+)_features\.csv$", p.name)    return int(m.group(1)) if m else Nonedef _pace_from_grid(grid_pos: pd.Series) -> pd.Series:    """Exponential drop from grid position, floored at S_MIN."""    g = pd.to_numeric(grid_pos, errors="coerce").to_numpy(dtype=float)    pace = S_MAX * np.power(0.5, (g - 1.0) / HALF_LIFE_POS)    pace = np.maximum(pace, S_MIN)    return pd.Series(pace, index=grid_pos.index)# ---------------- 1) FIND CURRENT (2025) DRIVERS ----------------files_2025 = sorted((ROOT / "2025").glob("2025_R*_features.csv"),                    key=lambda p: _parse_round_from_filename(p) or 999)if not files_2025:    raise RuntimeError("No 2025 features found under fastf1/2025/. Add at least one 2025 file to detect current drivers.")current_drivers = set()for p in files_2025:    df25 = pd.read_csv(p)    if DRIVER_COL not in df25.columns:        raise KeyError(f"'{DRIVER_COL}' not found in {p}. Available: {list(df25.columns)}")    current_drivers.update(df25[DRIVER_COL].dropna().astype(str).unique())current_drivers = sorted(current_drivers)# ---------------- 2) SCAN 2018..2025 FILES & COLLECT PACE ----------------records = []  # rows of (Driver, Event, Pace100)for y in YEARS:    year_dir = ROOT / f"{y}"    if not year_dir.exists():        continue    for p in year_dir.glob(f"{y}_R*_features.csv"):        df = pd.read_csv(p)        # Must have required columns        if not all(c in df.columns for c in [EVENT_COL, DRIVER_COL, GRID_COL]):            continue        # Get this file's event name; skip if not in 2025 calendar        ev_series = df[EVENT_COL].dropna().astype(str)        if ev_series.empty:            continue        ev_name = ev_series.iloc[0]        if ev_name not in ALLOWED_EVENTS:            continue        # Compute pace from grid        pace = _pace_from_grid(df[GRID_COL])        # stash        tmp = pd.DataFrame({            "Driver": df[DRIVER_COL].astype(str),            "Event": ev_name,            "Pace100": pace,        })        records.append(tmp)if not records:    raise RuntimeError("No pace rows collected. Check that your event names match the 2025 calendar and that required columns exist.")all_df = pd.concat(records, ignore_index=True)# ---------------- 3) FILTER TO CURRENT DRIVERS, AVERAGE MULTIPLE SEASONS ----------------all_df = all_df[all_df["Driver"].isin(current_drivers)]agg = all_df.groupby(["Driver", "Event"], as_index=False)["Pace100"].mean()# ---------------- 4) PIVOT TO DRIVER x GP, ENFORCE 2025 ORDER, FILL NEVER-RACED ----------------wide = agg.pivot_table(index="Driver", columns="Event", values="Pace100", aggfunc="mean")# Ensure full driver index & full 2025 calendar columnswide = wide.reindex(index=current_drivers, columns=EVENTS_2025_ORDER)# Never-raced cells become 15.24wide = wide.fillna(FILL_NEVER_RACED)# ---------------- 5) SAVE ----------------OUT_DIR.mkdir(parents=True, exist_ok=True)wide.to_csv(OUT_CSV, index=True)print(f"Built pace-by-track (grid-exp) for current 2025 drivers across 2025 calendar.")print(f"Rows (drivers): {wide.shape[0]} | Columns (GPs): {wide.shape[1]}")print(f"Saved -> {OUT_CSV}")# ... after building 'wide' (the Driver x GP pace table) ...# drop DOO if presentif "DOO" in wide.index:    wide = wide.drop("DOO", axis=0)# save as usualOUT_DIR.mkdir(parents=True, exist_ok=True)wide.to_csv(OUT_CSV, index=True)print(f"Saved pace table without DOO -> {OUT_CSV}")# reset index so Abbreviation is a column, then set backwide = wide.rename_axis("Abbreviation").reset_index()# save with Abbreviation as the first columnOUT_DIR.mkdir(parents=True, exist_ok=True)wide.to_csv(OUT_CSV, index=False)print(f"Saved with 'Abbreviation' as the driver column -> {OUT_CSV}")            #-----------------------------------------# driver_dnf_prob#-----------------------------------------ROOT = Path.home() / "Documents" / "F1-Project-Folder"SRC  = ROOT / "Data_Processed" / "prediction_data" / "dnf_chance_2025_R17_features.csv"DST_DIR = ROOT / "Data_Processed" / "wdc_prediction"DST_DIR.mkdir(parents=True, exist_ok=True)# --- load & tidy ---df = pd.read_csv(SRC)# keep only what we need; normalize column names# your file typically has: Abbreviation, p_final (the DNF probability)keep = ["Abbreviation"]if "p_final" in df.columns:    df["DNFProb"] = pd.to_numeric(df["p_final"], errors="coerce").fillna(0.0)    keep.append("DNFProb")elif "DNFProb" in df.columns:    df["DNFProb"] = pd.to_numeric(df["DNFProb"], errors="coerce").fillna(0.0)    keep.append("DNFProb")else:    # fallback: if nothing found, just copy raw with a safe name    keep = df.columns.tolist()df = df[keep].copy()# --- save with a stable name used by the WDC simulator ---out_path = DST_DIR / "dnf_chance_matrix.csv"df.to_csv(out_path, index=False)print(f"✅ DNF chance copied & standardized -> {out_path}")print(df.head(10).to_string(index=False))                #---------------------#Extra Driver Removal#----------------------ROOT = Path.home() / "Documents" / "F1-Project-Folder" / "Data_Processed" / "wdc_prediction"files = [    ROOT / "driver_vs_track_score_matrix.csv",    ROOT / "driver_vs_track_pace.csv",    ROOT / "dnf_chance_matrix.csv",]for f in files:    if f.exists():        df = pd.read_csv(f)        if "Abbreviation" in df.columns:            df = df[df["Abbreviation"] != "DOO"]        else:            # if driver names are in the index (matrix format)            if "DOO" in df.index:                df = df.drop(index="DOO")        df.to_csv(f, index=("Abbreviation" not in df.columns))        print(f"✅ Cleaned DOO from {f.name}")        #--------------------------------------------------------------------#Champ Rating (gives edge to championship leader and top drivers)#--------------------------------------------------------------------# ---- CONFIG ----YEAR_DIR  = Path("/Users/ravish/Documents/F1-Project-Folder/Data_Processed/fastf1/2025")WDC_DIR   = Path("/Users/ravish/Documents/F1-Project-Folder/Data_Processed/wdc_prediction")OUT_FILE  = WDC_DIR / "championship_rating_2025.csv"DRIVER_COL = "Abbreviation"POINTS_COL = "Points"          # fallback to FinishPosition if missingPOS_COL    = "FinishPosition"# Exponential-by-rank paramsH_CHAMP = 6.0    # half-life in rank positionsS_MIN   = 0.12   # rating floor# FIA race points (P1..P10; else 0)FIA_POINTS = {1:25, 2:18, 3:15, 4:12, 5:10, 6:8, 7:6, 8:4, 9:2, 10:1}def parse_round(p: Path):    m = re.search(r"_R(\d+)_features\.csv$", p.name)    return int(m.group(1)) if m else None# ---- Gather 2025 files ----files = sorted(YEAR_DIR.glob("2025_R*_features.csv"), key=lambda p: parse_round(p) or 999)if not files:    raise SystemExit(f"No feature files found in {YEAR_DIR}")# ---- Aggregate season points so far ----all_points = []for p in files:    df = pd.read_csv(p)    if DRIVER_COL not in df.columns:        print(f"Skip {p.name}: missing '{DRIVER_COL}'")        continue    if POINTS_COL in df.columns:        pts = pd.to_numeric(df[POINTS_COL], errors="coerce").fillna(0.0)    else:        if POS_COL not in df.columns:            print(f"Skip {p.name}: missing '{POINTS_COL}' and '{POS_COL}'")            continue        pos = pd.to_numeric(df[POS_COL], errors="coerce")        pts = pos.map(FIA_POINTS).fillna(0.0).astype(float)    all_points.append(pd.DataFrame({        "Abbreviation": df[DRIVER_COL].astype(str),        "Points": pts    }))agg = pd.concat(all_points, ignore_index=True).groupby("Abbreviation", as_index=False)["Points"].sum()# Drop DOO if presentagg = agg[agg["Abbreviation"] != "DOO"]# ---- Rank & compute Champ01 ----agg = agg.sort_values("Points", ascending=False).reset_index(drop=True)agg["Rank"] = agg.index + 1agg["Champ01"] = np.maximum(S_MIN, 0.5 ** ((agg["Rank"] - 1) / H_CHAMP))# ---- Save ----WDC_DIR.mkdir(parents=True, exist_ok=True)agg.to_csv(OUT_FILE, index=False)print(f"Championship rating saved -> {OUT_FILE}")print(agg.head(10))#-------------------------#Probability Calculator#-------------------------ROOT = Path("/Users/ravish/Documents/F1-Project-Folder/Data_Processed")WDC_DIR = ROOT / "wdc_prediction"PACE_CSV   = WDC_DIR / "pace_by_track_gridexp_2018to2025.csv"TRACK_CSV  = WDC_DIR / "driver_vs_track_score_matrix.csv"DNF_CSV    = WDC_DIR / "dnf_chance_matrix.csv"FORM_CSV   = ROOT / "driver_stats_over_years/current_driver_stats_2025.csv"CHAMP_CSV  = WDC_DIR / "championship_rating_2025.csv"OUT_WINPROB_CSV = WDC_DIR / "win_probabilities_remaining_2025.csv"# ---------- CONFIG: 2025 calendar & remaining ----------EVENTS_2025_ORDER = [    "Australian Grand Prix","Bahrain Grand Prix","Saudi Arabian Grand Prix","Japanese Grand Prix",    "Chinese Grand Prix","Miami Grand Prix","Emilia Romagna Grand Prix","Monaco Grand Prix",    "Canadian Grand Prix","Spanish Grand Prix","Austrian Grand Prix","British Grand Prix",    "Hungarian Grand Prix","Belgian Grand Prix","Dutch Grand Prix","Italian Grand Prix",    "Azerbaijan Grand Prix","Singapore Grand Prix","United States Grand Prix","Mexico City Grand Prix",    "São Paulo Grand Prix","Las Vegas Grand Prix","Qatar Grand Prix","Abu Dhabi Grand Prix"]CURRENT_ROUND = 17   # Azerbaijan just finished → start from Singapore# ---------- CONFIG: weights (a–e) & softmax ----------a = 0.15  # Paceb = 0.20  # Trackc = 0.20  # Formd = 0.10  # Survivale = 0.35  # Championship PerformanceTEMP    = 3.0MIN_PROB = 1e-12# normalize weightsw_sum = a + b + c + d + ea, b, c, d, e = (a/w_sum, b/w_sum, c/w_sum, d/w_sum, e/w_sum)# ---------- load inputs ----------pace   = pd.read_csv(PACE_CSV, index_col=0)track  = pd.read_csv(TRACK_CSV, index_col=0)dnf    = pd.read_csv(DNF_CSV, index_col=0)form   = pd.read_csv(FORM_CSV)   # Abbreviation, RollingFormchamp  = pd.read_csv(CHAMP_CSV)  # Abbreviation, Champ01# remaining eventsremaining_events = EVENTS_2025_ORDER[CURRENT_ROUND:]if not remaining_events:    raise SystemExit("No remaining events selected. Adjust CURRENT_ROUND.")# enforce consistent driversdrivers = set(pace.index) & set(track.index) & set(form["Abbreviation"]) & set(champ["Abbreviation"])if "DNFProb" in dnf.columns or any(ev in dnf.columns for ev in remaining_events):    drivers &= set(dnf.index)drivers = sorted(drivers)# drop DOOif "DOO" in drivers:    drivers.remove("DOO")form  = form.set_index("Abbreviation").loc[drivers]champ = champ.set_index("Abbreviation").loc[drivers]# ---------- ensure events exist ----------for ev in remaining_events:    if ev not in pace.columns:  pace[ev]  = np.nan    if ev not in track.columns: track[ev] = np.nanpace  = pace[remaining_events]track = track[remaining_events]# ---------- DNF handling ----------dnf_per_event = {}for ev in remaining_events:    if ev in dnf.columns:        dnf_per_event[ev] = dnf.loc[drivers, ev].astype(float)    elif "DNFProb" in dnf.columns:        dnf_per_event[ev] = dnf.loc[drivers, "DNFProb"].astype(float)    else:        dnf_per_event[ev] = pd.Series(0.0, index=drivers)# ---------- Compute win probabilities ----------form01  = (form["RollingForm"] / 100).fillna(0.0)champ01 = champ["Champ01"].fillna(0.0)win_prob = pd.DataFrame(index=drivers, columns=remaining_events, dtype=float)for ev in remaining_events:    pace01   = (pace[ev]  / 100).fillna(0.0)    track01  = (track[ev] / 100).fillna(0.0)    survival = (1.0 - dnf_per_event[ev]).clip(0,1).fillna(0.0)    score = (a*pace01           + b*track01           + c*form01           + d*survival           + e*champ01)    # softmax with temperature    x = score.values - np.max(score.values)    x = x / max(TEMP, 1e-12)    ex = np.exp(x)    p  = ex / ex.sum() if ex.sum() > 0 else np.zeros_like(ex)    p[p < MIN_PROB] = 0.0    win_prob[ev] = p# ---------- Save ----------WDC_DIR.mkdir(parents=True, exist_ok=True)win_prob_out = win_prob.rename_axis("Abbreviation").reset_index()win_prob_out.to_csv(OUT_WINPROB_CSV, index=False)print(f"Remaining events: {remaining_events}")print(f"Drivers: {len(win_prob.index)} | Saved -> {OUT_WINPROB_CSV}")#----------------------------# Monte Carlo First Runner#----------------------------# === STEP 2: Monte Carlo finishing position distribution ===import pandas as pdimport numpy as npfrom pathlib import Path# ---------- CONFIG ----------ROOT = Path("/Users/ravish/Documents/F1-Project-Folder/Data_Processed/wdc_prediction")WINPROB_CSV = ROOT / "win_probabilities_remaining_2025.csv"OUT_FINPOS_CSV = ROOT / "finish_position_probabilities_2025.csv"N_SIM = 1_000_000   # number of Monte Carlo runsMIN_PROB = 1e-5     # threshold: values below become 0# ---------- load win prob table ----------win_probs = pd.read_csv(WINPROB_CSV, index_col=0)   # Abbreviation × GPdrivers = win_probs.index.tolist()events = win_probs.columns.tolist()n_drivers = len(drivers)# ---------- function: sample one finishing order via Plackett–Luce ----------def sample_order(probs):            """probs = Series of win probs for a race (drivers × 1)."""            weights = probs.values.astype(float)    weights = np.clip(weights, 1e-12, None)  # avoid 0    order = []    available = list(range(len(weights)))    while available:        w = weights[available]        w = w / w.sum()        pick = np.random.choice(available, p=w)        order.append(pick)        available.remove(pick)    return order  # list of indices in finishing order#triple quote to stop sim# ---------- simulate ----------results = {}for ev in events:    print(f"Simulating {ev} with {N_SIM:,} runs...")    counts = np.zeros((n_drivers, n_drivers), dtype=np.int64)  # driver × position        probs_ev = win_probs[ev]    for _ in range(N_SIM):        order = sample_order(probs_ev)        for pos, idx in enumerate(order):            counts[idx, pos] += 1        probs_matrix = counts / N_SIM    df_ev = pd.DataFrame(probs_matrix, index=drivers,                         columns=[f"P{p+1}" for p in range(n_drivers)])    df_ev[df_ev < MIN_PROB] = 0.0    results[ev] = df_ev        #triple quote so sim don't run everytime# ---------- save combined ----------# multiindex columns: (Event, P1..Pn)final = pd.concat(results, axis=1)OUT_FINPOS_CSV.parent.mkdir(parents=True, exist_ok=True)final.to_csv(OUT_FINPOS_CSV)print(f"Saved finishing position probabilities -> {OUT_FINPOS_CSV}")#-----------------------------# Monte - Carlo Runner 2#-----------------------------# ---------- CONFIG ----------WDC_DIR = Path("/Users/ravish/Documents/F1-Project-Folder/Data_Processed/wdc_prediction")IN_POSPROB = WDC_DIR / "finish_position_probabilities_2025.csv"OUT_DIR = WDC_DIR / "final_orders_10m"N_SIM = 100_000_000MIN_PROB = 1e-12# ---------- LOAD (MultiIndex columns: (Event, P1..P20)) ----------posprob = pd.read_csv(IN_POSPROB, index_col=0, header=[0, 1])drivers = posprob.index.to_numpy()events = posprob.columns.get_level_values(0).unique()# ---------- helper to simulate one position ----------def simulate_position(probs, active_mask, n_sim=N_SIM):    p = probs.copy().astype(float)    p[~active_mask] = 0.0    p[p < MIN_PROB] = 0.0    s = p.sum()    if s <= 0:        # fallback: highest original prob among active        cand = np.where(active_mask)[0]        return int(cand[np.argmax(probs[cand])])    p /= s    draws = np.random.choice(len(p), size=n_sim, p=p)    counts = np.bincount(draws, minlength=len(p))    counts[~active_mask] = -1    return int(np.argmax(counts))# ---------- simulate for each event ----------OUT_DIR.mkdir(parents=True, exist_ok=True)for ev in events:    print(f"Simulating final order for {ev}...")    event_df = posprob[ev].copy()    # Ensure columns are in P1..P20 order    cols_sorted = sorted(        event_df.columns,        key=lambda s: int(s[1:]) if (s.startswith("P") and s[1:].isdigit()) else 999    )    event_df = event_df[cols_sorted]    M = event_df.to_numpy(dtype=float)         # shape: n_drivers x n_positions    n_drivers, n_positions = M.shape    active = np.ones(n_drivers, dtype=bool)    finishing_order_idxs = []    finishing_order_names = []    for k in range(n_positions):               # P1..Pn        idx = simulate_position(M[:, k], active, N_SIM)        finishing_order_idxs.append(idx)        finishing_order_names.append(drivers[idx])        active[idx] = False    # Build per-event CSV: include GP name column    out_df = pd.DataFrame({        "GrandPrix": [ev] * len(finishing_order_names),        "Position":  [f"P{i+1}" for i in range(len(finishing_order_names))],        "Abbreviation": finishing_order_names    })    safe_event = ev.replace(" ", "_").replace("/", "-")    out_path = OUT_DIR / f"final_order_{safe_event}.csv"    out_df.to_csv(out_path, index=False)    print(f"  -> saved {out_path}")    